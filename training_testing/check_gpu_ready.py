#!/usr/bin/env python3
"""
æ£€æŸ¥GPUçŠ¶æ€å’Œå†…å­˜ï¼Œç¡®ä¿å¯ä»¥è¿›è¡Œ4å¡è®­ç»ƒ
"""

import torch
import subprocess
import sys

def check_gpu_status():
    """æ£€æŸ¥GPUæ˜¯å¦å‡†å¤‡å¥½è¿›è¡Œè®­ç»ƒ"""
    
    print("="*60)
    print("GPUçŠ¶æ€æ£€æŸ¥")
    print("="*60)
    
    # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼è¯·æ£€æŸ¥é©±åŠ¨å’ŒPyTorchå®‰è£…ã€‚")
        return False
    
    # æ£€æŸ¥GPUæ•°é‡
    gpu_count = torch.cuda.device_count()
    print(f"âœ… æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
    
    if gpu_count < 4:
        print(f"âš ï¸  è­¦å‘Šï¼šåªæœ‰{gpu_count}ä¸ªGPUï¼Œéœ€è¦4ä¸ªGPUè¿›è¡Œè®­ç»ƒ")
        print("   å¯ä»¥ä¿®æ”¹CUDA_VISIBLE_DEVICESæ¥æŒ‡å®šè¦ä½¿ç”¨çš„GPU")
        
    # æ£€æŸ¥æ¯ä¸ªGPUçš„çŠ¶æ€
    print("\nğŸ“Š GPUè¯¦ç»†ä¿¡æ¯:")
    print("-"*40)
    
    total_memory_gb = 0
    available_memory_gb = 0
    
    for i in range(gpu_count):
        torch.cuda.set_device(i)
        props = torch.cuda.get_device_properties(i)
        
        # è·å–å†…å­˜ä¿¡æ¯
        total_mem = props.total_memory / (1024**3)  # è½¬æ¢ä¸ºGB
        allocated = torch.cuda.memory_allocated(i) / (1024**3)
        free = (props.total_memory - torch.cuda.memory_allocated(i)) / (1024**3)
        
        total_memory_gb += total_mem
        available_memory_gb += free
        
        print(f"\nGPU {i}: {props.name}")
        print(f"  æ€»å†…å­˜: {total_mem:.1f} GB")
        print(f"  å·²ä½¿ç”¨: {allocated:.1f} GB")
        print(f"  å¯ç”¨: {free:.1f} GB")
        
        # æ£€æŸ¥å†…å­˜æ˜¯å¦è¶³å¤Ÿ
        if free < 20:  # å°‘äº20GBå¯èƒ½ä¸å¤Ÿ
            print(f"  âš ï¸ å†…å­˜å¯èƒ½ä¸è¶³ï¼Œå»ºè®®è‡³å°‘20GBå¯ç”¨å†…å­˜")
    
    # ä¼°ç®—è®­ç»ƒéœ€æ±‚
    print("\nğŸ’¡ è®­ç»ƒé…ç½®ä¼°ç®—:")
    print("-"*40)
    
    batch_size = 2
    max_length = 8192
    model_size_gb = 16  # InternVL2.5-8Bå¤§çº¦16GB
    
    # æ¯ä¸ªGPUçš„å†…å­˜éœ€æ±‚ä¼°ç®—
    per_gpu_requirement = model_size_gb + (batch_size * max_length * 4 / (1024**3))  # ç®€å•ä¼°ç®—
    
    print(f"æ¨¡å‹å¤§å°: ~{model_size_gb} GB")
    print(f"Batch size per GPU: {batch_size}")
    print(f"Max sequence length: {max_length}")
    print(f"é¢„ä¼°æ¯GPUå†…å­˜éœ€æ±‚: ~{per_gpu_requirement:.1f} GB")
    
    if gpu_count >= 4:
        print(f"\nâœ… 4å¡è®­ç»ƒé…ç½®:")
        print(f"  - æ€»batch size: {4 * batch_size} (æ¯å¡{batch_size})")
        print(f"  - Gradient accumulation: 2")
        print(f"  - æœ‰æ•ˆbatch size: {4 * batch_size * 2} = {4 * batch_size * 2}")
    
    # æ£€æŸ¥nvidia-smi
    print("\nğŸ“ˆ nvidia-smi è¾“å‡º:")
    print("-"*40)
    try:
        result = subprocess.run(['nvidia-smi', '--query-gpu=index,name,memory.used,memory.free,memory.total', 
                               '--format=csv,noheader,nounits'], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            for line in lines:
                parts = line.split(', ')
                if len(parts) >= 5:
                    idx, name, used, free, total = parts
                    print(f"GPU {idx}: {name} - å·²ç”¨:{used}MB, å¯ç”¨:{free}MB, æ€»è®¡:{total}MB")
        else:
            print("æ— æ³•è¿è¡Œnvidia-smi")
    except:
        print("nvidia-smiä¸å¯ç”¨")
    
    # æœ€ç»ˆå»ºè®®
    print("\n" + "="*60)
    print("å»ºè®®:")
    print("="*60)
    
    if gpu_count >= 4 and available_memory_gb/gpu_count > 20:
        print("âœ… GPUçŠ¶æ€è‰¯å¥½ï¼Œå¯ä»¥å¼€å§‹4å¡è®­ç»ƒï¼")
        print("\nå¯åŠ¨å‘½ä»¤:")
        print("  bash launch_4gpu_training.sh")
        return True
    elif gpu_count < 4:
        print(f"âš ï¸ åªæœ‰{gpu_count}ä¸ªGPUï¼Œå¯ä»¥è°ƒæ•´è®­ç»ƒé…ç½®:")
        print(f"  - ä¿®æ”¹launchè„šæœ¬ä¸­çš„--nproc_per_node={gpu_count}")
        print(f"  - æˆ–è®¾ç½®CUDA_VISIBLE_DEVICESé€‰æ‹©ç‰¹å®šGPU")
        return False
    else:
        print("âš ï¸ GPUå†…å­˜å¯èƒ½ä¸è¶³ï¼Œå»ºè®®:")
        print("  - å‡å°batch_sizeåˆ°1")
        print("  - å‡å°max_length")
        print("  - å¯ç”¨gradient_checkpointing")
        print("  - ä½¿ç”¨8bité‡åŒ–")
        return False

if __name__ == "__main__":
    ready = check_gpu_status()
    sys.exit(0 if ready else 1)