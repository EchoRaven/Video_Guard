#!/usr/bin/env python3
"""
éªŒè¯InternVL3-8Bæ¨¡å‹è®¾ç½®
"""

import torch
from transformers import AutoTokenizer, AutoModel
import sys

def verify_internvl3():
    """éªŒè¯InternVL3-8Bé…ç½®"""
    
    print("="*80)
    print("InternVL3-8B æ¨¡å‹é…ç½®éªŒè¯")
    print("="*80)
    
    model_name = "OpenGVLab/InternVL3-8B"
    
    print(f"\nğŸ“¦ æ¨¡å‹: {model_name}")
    print("-"*40)
    
    # æ£€æŸ¥æ¨¡å‹ä¿¡æ¯
    print("\n1ï¸âƒ£ æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§...")
    try:
        # åªåŠ è½½tokenizerå’Œconfigï¼Œä¸åŠ è½½æƒé‡
        print("   åŠ è½½tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(
            model_name,
            trust_remote_code=True,
            use_fast=False
        )
        print("   âœ… TokenizeråŠ è½½æˆåŠŸ")
        
        # æ£€æŸ¥ç‰¹æ®Štokens
        special_tokens = {
            '<IMG_CONTEXT>': tokenizer.convert_tokens_to_ids('<IMG_CONTEXT>'),
            '<img>': tokenizer.convert_tokens_to_ids('<img>'),
            '</img>': tokenizer.convert_tokens_to_ids('</img>'),
            '<|vision_end|>': tokenizer.convert_tokens_to_ids('<|vision_end|>')
        }
        
        print("\n2ï¸âƒ£ ç‰¹æ®ŠToken IDs:")
        for token, token_id in special_tokens.items():
            if token_id != tokenizer.unk_token_id:
                print(f"   {token}: {token_id} âœ…")
            else:
                print(f"   {token}: NOT FOUND âŒ")
        
    except Exception as e:
        print(f"   âŒ é”™è¯¯: {e}")
        return False
    
    print("\n3ï¸âƒ£ æ¨¡å‹å‚æ•°:")
    print(f"   â€¢ æ¨¡å‹å¤§å°: ~8Bå‚æ•°")
    print(f"   â€¢ è§†è§‰ç¼–ç å™¨: InternViT-300M")
    print(f"   â€¢ è¯­è¨€æ¨¡å‹: Qwen2.5-7B-Instruct")
    print(f"   â€¢ æ¯patch tokens: 256")
    print(f"   â€¢ æ”¯æŒåŠ¨æ€åˆ†è¾¨ç‡: æ˜¯")
    print(f"   â€¢ æœ€å¤§patches: 12 (æ¨è6)")
    
    print("\n4ï¸âƒ£ è®­ç»ƒé…ç½®å»ºè®®:")
    print(f"   â€¢ LoRA rank: 128 (å¯ä»¥ç”¨32-256)")
    print(f"   â€¢ Learning rate: 1e-4")
    print(f"   â€¢ Batch size per GPU: 1-2")
    print(f"   â€¢ Max sequence length: 8192")
    print(f"   â€¢ Gradient checkpointing: å¯ç”¨")
    print(f"   â€¢ BF16: å¯ç”¨")
    
    print("\n5ï¸âƒ£ å†…å­˜ä¼°ç®— (æ¯GPU):")
    model_memory = 16  # GB
    batch_memory = 2   # GB for batch_size=2
    optimizer_memory = 5  # GB
    total = model_memory + batch_memory + optimizer_memory
    print(f"   â€¢ æ¨¡å‹: ~{model_memory} GB")
    print(f"   â€¢ Batch (size=2): ~{batch_memory} GB")
    print(f"   â€¢ ä¼˜åŒ–å™¨çŠ¶æ€: ~{optimizer_memory} GB")
    print(f"   â€¢ æ€»è®¡: ~{total} GB")
    print(f"   â€¢ H200å¯ç”¨: 140 GB âœ…")
    
    print("\n" + "="*80)
    print("âœ… InternVL3-8B é…ç½®éªŒè¯å®Œæˆï¼")
    print("\nå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨è®­ç»ƒ:")
    print("  â€¢ æµ‹è¯•: bash launch_single_gpu_test.sh")
    print("  â€¢ 4å¡è®­ç»ƒ: bash launch_4gpu_training.sh")
    
    return True

if __name__ == "__main__":
    success = verify_internvl3()
    sys.exit(0 if success else 1)