#!/usr/bin/env python3
"""
æ£€æŸ¥å®é™…è®­ç»ƒæ•°æ®é‡
"""

import sys
sys.path.append('/scratch/czr/Video-Guard/training_testing')

from Dataloader import StreamingDataset
import json

def check_data_volume():
    """æ£€æŸ¥å®é™…ä¼šåŠ è½½çš„æ•°æ®é‡"""
    
    print("="*80)
    print("è®­ç»ƒæ•°æ®é‡ç»Ÿè®¡")
    print("="*80)
    
    # æ£€æŸ¥åŸå§‹æ•°æ®é‡
    print("\nğŸ“Š åŸå§‹æ•°æ®é‡:")
    print("-"*40)
    
    # Shot2Story
    shot2story_path = '/scratch/czr/Video-Guard/datasets/shot2story/134k_full_train.json'
    with open(shot2story_path, 'r') as f:
        shot2story_data = json.load(f)
    
    total_shot2story_videos = len(shot2story_data)
    
    # è®¡ç®—Shot2Storyçš„clipsæ•°é‡
    total_shot2story_clips = 0
    for video in shot2story_data[:1000]:  # é‡‡æ ·è®¡ç®—å¹³å‡å€¼
        if 'video_names' in video:
            total_shot2story_clips += len(video['video_names'])
    avg_clips_per_video = total_shot2story_clips / min(1000, len(shot2story_data))
    estimated_total_clips = int(total_shot2story_videos * avg_clips_per_video)
    
    print(f"Shot2Story:")
    print(f"  â€¢ æ€»è§†é¢‘æ•°: {total_shot2story_videos:,}")
    print(f"  â€¢ å¹³å‡æ¯è§†é¢‘clipsæ•°: {avg_clips_per_video:.1f}")
    print(f"  â€¢ é¢„ä¼°æ€»clipsæ•°: {estimated_total_clips:,}")
    
    # SafeWatch
    safewatch_path = '/scratch/czr/Video-Guard/datasets/safewatch_streaming_corrected.jsonl'
    total_safewatch_videos = 0
    total_safewatch_clips = 0
    
    with open(safewatch_path, 'r') as f:
        for line in f:
            total_safewatch_videos += 1
            data = json.loads(line)
            total_safewatch_clips += len(data.get('clip_video_paths', []))
    
    print(f"\nSafeWatch:")
    print(f"  â€¢ æ€»è§†é¢‘æ•°: {total_safewatch_videos:,}")
    print(f"  â€¢ æ€»clipsæ•°: {total_safewatch_clips:,}")
    print(f"  â€¢ å¹³å‡æ¯è§†é¢‘clipsæ•°: {total_safewatch_clips/total_safewatch_videos:.1f}")
    
    # åŠ è½½å®é™…æ•°æ®é›†çœ‹ä¼šä½¿ç”¨å¤šå°‘
    print("\nğŸ“¦ å®é™…åŠ è½½çš„æ•°æ®é‡ (æ ¹æ®é…ç½®):")
    print("-"*40)
    
    # ä½¿ç”¨é…ç½®çš„é™åˆ¶
    max_samples_config = [200000, 20000]  # [shot2story, safewatch]
    
    print(f"é…ç½®çš„é™åˆ¶:")
    print(f"  â€¢ Shot2Story: {max_samples_config[0]:,} ä¸ªè§†é¢‘")
    print(f"  â€¢ SafeWatch: {max_samples_config[1]:,} ä¸ªè§†é¢‘")
    
    # å®é™…èƒ½åŠ è½½çš„æ•°é‡
    actual_shot2story = min(max_samples_config[0], total_shot2story_videos)
    actual_safewatch = min(max_samples_config[1], total_safewatch_videos)
    
    print(f"\nå®é™…ä¼šåŠ è½½:")
    print(f"  â€¢ Shot2Story: {actual_shot2story:,} ä¸ªè§†é¢‘ (å…¨éƒ¨)")
    print(f"  â€¢ SafeWatch: {actual_safewatch:,} ä¸ªè§†é¢‘ (å…¨éƒ¨)")
    
    # ä¼°ç®—æ ·æœ¬æ•°é‡
    estimated_shot2story_samples = int(actual_shot2story * avg_clips_per_video) + actual_shot2story  # clips + final responses
    estimated_safewatch_samples = total_safewatch_clips + actual_safewatch  # clips + final responses
    
    print(f"\né¢„ä¼°è®­ç»ƒæ ·æœ¬æ•°:")
    print(f"  â€¢ Shot2Storyæ ·æœ¬: ~{estimated_shot2story_samples:,}")
    print(f"  â€¢ SafeWatchæ ·æœ¬: ~{estimated_safewatch_samples:,}")
    print(f"  â€¢ æ€»è®¡: ~{estimated_shot2story_samples + estimated_safewatch_samples:,} ä¸ªæ ·æœ¬")
    
    # è®­ç»ƒæ—¶é—´ä¼°ç®—
    print("\nâ±ï¸ è®­ç»ƒæ—¶é—´ä¼°ç®— (4å¡, batch_size=2):")
    print("-"*40)
    
    total_samples = estimated_shot2story_samples + estimated_safewatch_samples
    batch_size_per_gpu = 2
    num_gpus = 4
    gradient_accumulation = 2
    effective_batch_size = batch_size_per_gpu * num_gpus * gradient_accumulation  # 16
    
    steps_per_epoch = total_samples // effective_batch_size
    num_epochs = 3
    total_steps = steps_per_epoch * num_epochs
    
    # å‡è®¾æ¯æ­¥0.5-1ç§’
    min_time_hours = (total_steps * 0.5) / 3600
    max_time_hours = (total_steps * 1.0) / 3600
    
    print(f"  â€¢ æ¯epochæ­¥æ•°: {steps_per_epoch:,}")
    print(f"  â€¢ æ€»æ­¥æ•° (3 epochs): {total_steps:,}")
    print(f"  â€¢ é¢„ä¼°è®­ç»ƒæ—¶é—´: {min_time_hours:.1f} - {max_time_hours:.1f} å°æ—¶")
    
    # å†…å­˜ä¼°ç®—
    print("\nğŸ’¾ å†…å­˜ä½¿ç”¨ä¼°ç®—:")
    print("-"*40)
    
    model_size_gb = 16  # InternVL2.5-8B
    per_sample_memory_mb = 100  # ç²—ç•¥ä¼°ç®—æ¯ä¸ªæ ·æœ¬100MB
    batch_memory_gb = (batch_size_per_gpu * per_sample_memory_mb) / 1024
    
    total_memory_per_gpu = model_size_gb + batch_memory_gb + 5  # +5GB for optimizer states
    
    print(f"  â€¢ æ¨¡å‹å¤§å°: {model_size_gb} GB")
    print(f"  â€¢ Batchå†…å­˜: ~{batch_memory_gb:.1f} GB")
    print(f"  â€¢ æ¯GPUæ€»éœ€æ±‚: ~{total_memory_per_gpu:.1f} GB")
    print(f"  â€¢ H200å¯ç”¨å†…å­˜: 140 GB (å……è¶³)")
    
    print("\n" + "="*80)
    print("âœ… æ•°æ®é…ç½®å®Œæˆï¼")
    print(f"å°†ä½¿ç”¨å…¨éƒ¨ {actual_shot2story:,} ä¸ªShot2Storyè§†é¢‘å’Œå…¨éƒ¨ {actual_safewatch:,} ä¸ªSafeWatchè§†é¢‘è¿›è¡Œè®­ç»ƒ")

if __name__ == "__main__":
    check_data_volume()